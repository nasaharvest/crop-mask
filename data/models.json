{
    "Ethiopia_Bure_Jimma_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/z0z89qfd",
        "test_metrics": {
            "accuracy": 0.8574,
            "f1_score": 0.8044,
            "precision_score": 0.7228,
            "recall_score": 0.9068,
            "roc_auc_score": 0.9365
        },
        "val_metrics": {
            "accuracy": 0.8627,
            "f1_score": 0.8362,
            "precision_score": 0.7773,
            "recall_score": 0.9048,
            "roc_auc_score": 0.9393
        }
    },
    "Ethiopia_Bure_Jimma_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/0yporfjp",
        "test_metrics": {
            "accuracy": 0.9143,
            "f1_score": 0.8592,
            "precision_score": 0.8041,
            "recall_score": 0.9225,
            "roc_auc_score": 0.9636
        },
        "val_metrics": {
            "accuracy": 0.8903,
            "f1_score": 0.8073,
            "precision_score": 0.7351,
            "recall_score": 0.8952,
            "roc_auc_score": 0.9571
        }
    },
    "Ethiopia_Tigray_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/h89pakgn",
        "test_metrics": {
            "accuracy": 0.8304,
            "f1_score": 0.6884,
            "precision_score": 0.6934,
            "recall_score": 0.6835,
            "roc_auc_score": 0.8502
        },
        "val_metrics": {
            "accuracy": 0.8308,
            "f1_score": 0.7179,
            "precision_score": 0.7,
            "recall_score": 0.7368,
            "roc_auc_score": 0.8805
        }
    },
    "Ethiopia_Tigray_2021": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/3ebyb5g6",
        "test_metrics": {
            "accuracy": 0.8242,
            "f1_score": 0.7193,
            "precision_score": 0.6891,
            "recall_score": 0.7523,
            "roc_auc_score": 0.8782
        },
        "val_metrics": {
            "accuracy": 0.8503,
            "f1_score": 0.744,
            "precision_score": 0.7857,
            "recall_score": 0.7064,
            "roc_auc_score": 0.8765
        }
    },
    "Kenya_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/sthnqh6i",
        "test_metrics": {
            "accuracy": 0.9345,
            "f1_score": 0.6667,
            "precision_score": 0.5806,
            "recall_score": 0.7826,
            "roc_auc_score": 0.941
        },
        "val_metrics": {
            "accuracy": 0.9463,
            "f1_score": 0.5556,
            "precision_score": 0.4348,
            "recall_score": 0.7692,
            "roc_auc_score": 0.9625
        }
    },
    "Malawi_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/ded0f7z5",
        "test_metrics": {
            "accuracy": 0.884,
            "f1_score": 0.5954,
            "precision_score": 0.6094,
            "recall_score": 0.5821,
            "roc_auc_score": 0.9179
        },
        "val_metrics": {
            "accuracy": 0.8612,
            "f1_score": 0.4516,
            "precision_score": 0.359,
            "recall_score": 0.6087,
            "roc_auc_score": 0.8784
        }
    },
    "Mali_lower_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/uownf4jk",
        "test_metrics": {
            "accuracy": 0.738,
            "f1_score": 0.6243,
            "precision_score": 0.6211,
            "recall_score": 0.6277,
            "roc_auc_score": 0.7766
        },
        "val_metrics": {
            "accuracy": 0.7818,
            "f1_score": 0.7196,
            "precision_score": 0.7333,
            "recall_score": 0.7064,
            "roc_auc_score": 0.8449
        }
    },
    "Namibia_North_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/0px6gsf3",
        "test_metrics": {
            "accuracy": 0.955,
            "f1_score": 0.0909,
            "precision_score": 0.0588,
            "recall_score": 0.2,
            "roc_auc_score": 0.8806
        },
        "val_metrics": {
            "accuracy": 0.9412,
            "f1_score": 0.1935,
            "precision_score": 0.125,
            "recall_score": 0.4286,
            "roc_auc_score": 0.8814
        }
    },
    "Namibia_North_V3": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/qzfflhy8",
        "test_metrics": {
            "accuracy": 0.9635,
            "f1_score": 0.1429,
            "precision_score": 0.0833,
            "recall_score": 0.5,
            "roc_auc_score": 0.8404
        },
        "val_metrics": {
            "accuracy": 0.9744,
            "f1_score": 0.1053,
            "precision_score": 0.0556,
            "recall_score": 1.0,
            "roc_auc_score": 0.9834
        }
    },
    "Rwanda_2019_skip_era5": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/a9kyjwwt",
        "test_metrics": {
            "accuracy": 0.7153,
            "f1_score": 0.5885,
            "precision_score": 0.5855,
            "recall_score": 0.5916,
            "roc_auc_score": 0.7784
        },
        "val_metrics": {
            "accuracy": 0.7288,
            "f1_score": 0.5937,
            "precision_score": 0.5886,
            "recall_score": 0.5988,
            "roc_auc_score": 0.7811
        }
    },
    "Senegal-2022": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/449eoh51",
        "test_metrics": {
            "accuracy": 0.8982,
            "f1_score": 0.4615,
            "precision_score": 0.5333,
            "recall_score": 0.4068,
            "roc_auc_score": 0.8485
        },
        "val_metrics": {
            "accuracy": 0.9612,
            "f1_score": 0.697,
            "precision_score": 0.7188,
            "recall_score": 0.6765,
            "roc_auc_score": 0.9536
        }
    },
    "Senegal_2022_v1": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/evr7pr86",
        "test_metrics": {
            "accuracy": 0.8475,
            "f1_score": 0.4364,
            "precision_score": 0.48,
            "recall_score": 0.4,
            "roc_auc_score": 0.8714
        },
        "val_metrics": {
            "accuracy": 0.9102,
            "f1_score": 0.6119,
            "precision_score": 0.6212,
            "recall_score": 0.6029,
            "roc_auc_score": 0.9128
        }
    },
    "Sudan_Al_Gadaref_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/a2kkq4fs",
        "test_metrics": {
            "accuracy": 0.8735,
            "f1_score": 0.8459,
            "precision_score": 0.8194,
            "recall_score": 0.8741,
            "roc_auc_score": 0.9432
        },
        "val_metrics": {
            "accuracy": 0.8544,
            "f1_score": 0.8067,
            "precision_score": 0.7619,
            "recall_score": 0.8571,
            "roc_auc_score": 0.9393
        }
    },
    "Sudan_Al_Gadaref_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/leg0btix",
        "test_metrics": {
            "accuracy": 0.85,
            "f1_score": 0.8571,
            "precision_score": 0.8219,
            "recall_score": 0.8955,
            "roc_auc_score": 0.9205
        },
        "val_metrics": {
            "accuracy": 0.8586,
            "f1_score": 0.867,
            "precision_score": 0.8224,
            "recall_score": 0.9167,
            "roc_auc_score": 0.933
        }
    },
    "Sudan_Blue_Nile_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/u7z0fftu",
        "test_metrics": {
            "accuracy": 0.9411,
            "f1_score": 0.9086,
            "precision_score": 0.9277,
            "recall_score": 0.8902,
            "roc_auc_score": 0.9875
        },
        "val_metrics": {
            "accuracy": 0.9486,
            "f1_score": 0.9257,
            "precision_score": 0.9205,
            "recall_score": 0.931,
            "roc_auc_score": 0.982
        }
    },
    "Sudan_Blue_Nile_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/sqanaaf6",
        "test_metrics": {
            "accuracy": 0.9379,
            "f1_score": 0.888,
            "precision_score": 0.8333,
            "recall_score": 0.9504,
            "roc_auc_score": 0.9796
        },
        "val_metrics": {
            "accuracy": 0.9028,
            "f1_score": 0.8263,
            "precision_score": 0.7329,
            "recall_score": 0.9469,
            "roc_auc_score": 0.9638
        }
    },
    "Sudan_South_2022": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/h4fwsvrt",
        "test_metrics": {
            "accuracy": 0.8429,
            "f1_score": 0.4762,
            "precision_score": 0.4545,
            "recall_score": 0.5,
            "roc_auc_score": 0.8113
        },
        "val_metrics": {
            "accuracy": 0.8593,
            "f1_score": 0.5957,
            "precision_score": 0.7,
            "recall_score": 0.5185,
            "roc_auc_score": 0.8776
        }
    },
    "Tanzania_February_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/3aept9rs",
        "test_metrics": {
            "accuracy": 0.8552,
            "f1_score": 0.7437,
            "precision_score": 0.8152,
            "recall_score": 0.6837,
            "roc_auc_score": 0.9203
        },
        "val_metrics": {
            "accuracy": 0.8513,
            "f1_score": 0.7406,
            "precision_score": 0.8007,
            "recall_score": 0.6889,
            "roc_auc_score": 0.9076
        }
    },
    "Tanzania_September_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/ri13nskv",
        "test_metrics": {
            "accuracy": 0.8581,
            "f1_score": 0.7515,
            "precision_score": 0.8138,
            "recall_score": 0.6981,
            "roc_auc_score": 0.9169
        },
        "val_metrics": {
            "accuracy": 0.8488,
            "f1_score": 0.7311,
            "precision_score": 0.8092,
            "recall_score": 0.6667,
            "roc_auc_score": 0.9112
        }
    },
    "Togo_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/spekm4d0",
        "test_metrics": {
            "accuracy": 0.7806,
            "f1_score": 0.7302,
            "precision_score": 0.6345,
            "recall_score": 0.8598,
            "roc_auc_score": 0.887
        },
        "val_metrics": {
            "accuracy": 0.8955,
            "f1_score": 0.9028,
            "precision_score": 0.8609,
            "recall_score": 0.9489,
            "roc_auc_score": 0.9684
        }
    },
    "Uganda_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/dlztexn6",
        "test_metrics": {
            "accuracy": 0.8377,
            "f1_score": 0.5067,
            "precision_score": 0.3878,
            "recall_score": 0.7308,
            "roc_auc_score": 0.8863
        },
        "val_metrics": {
            "accuracy": 0.8458,
            "f1_score": 0.5205,
            "precision_score": 0.4419,
            "recall_score": 0.6333,
            "roc_auc_score": 0.8442
        }
    },
    "Uganda_North_2022_V1": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/v5f8m489",
        "test_metrics": {
            "accuracy": 0.8018,
            "f1_score": 0.6457,
            "precision_score": 0.5775,
            "recall_score": 0.7321,
            "roc_auc_score": 0.8606
        },
        "val_metrics": {
            "accuracy": 0.7982,
            "f1_score": 0.6667,
            "precision_score": 0.6571,
            "recall_score": 0.6765,
            "roc_auc_score": 0.8647
        }
    },
    "Zambia_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/rnhjdn44",
        "test_metrics": {
            "accuracy": 0.9589,
            "f1_score": 0.5,
            "precision_score": 0.5625,
            "recall_score": 0.45,
            "roc_auc_score": 0.9672
        },
        "val_metrics": {
            "accuracy": 0.9548,
            "f1_score": 0.4,
            "precision_score": 0.4,
            "recall_score": 0.4,
            "roc_auc_score": 0.9511
        }
    },
    "Zambia_2019_v2": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/gqni0fso",
        "test_metrics": {
            "accuracy": 0.968,
            "f1_score": 0.65,
            "precision_score": 0.65,
            "recall_score": 0.65,
            "roc_auc_score": 0.9349
        },
        "val_metrics": {
            "accuracy": 0.9724,
            "f1_score": 0.6452,
            "precision_score": 0.625,
            "recall_score": 0.6667,
            "roc_auc_score": 0.9363
        }
    }
}
