{
    "DemoMay10": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/2yssv9nz",
        "test_metrics": {
            "accuracy": 0.8219,
            "f1_score": 0.7781,
            "precision_score": 0.7145,
            "recall_score": 0.8543,
            "roc_auc_score": 0.9121
        },
        "val_metrics": {
            "accuracy": 0.8209,
            "f1_score": 0.784,
            "precision_score": 0.7307,
            "recall_score": 0.8458,
            "roc_auc_score": 0.9067
        }
    },
    "East_Africa": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/17mf1r6r",
        "test_metrics": {
            "accuracy": 0.8597,
            "f1_score": 0.8116,
            "precision_score": 0.7972,
            "recall_score": 0.8265,
            "roc_auc_score": 0.9318
        },
        "val_metrics": {
            "accuracy": 0.8494,
            "f1_score": 0.8041,
            "precision_score": 0.8039,
            "recall_score": 0.8044,
            "roc_auc_score": 0.9224
        }
    },
    "Ethiopia_Bure_Jimma_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/2zy7gz56",
        "test_metrics": {
            "accuracy": 0.9004,
            "f1_score": 0.8717,
            "precision_score": 0.8402,
            "recall_score": 0.9056,
            "roc_auc_score": 0.9543
        },
        "val_metrics": {
            "accuracy": 0.8948,
            "f1_score": 0.854,
            "precision_score": 0.8031,
            "recall_score": 0.9118,
            "roc_auc_score": 0.954
        }
    },
    "Ethiopia_Bure_Jimma_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/wnlknhn3",
        "test_metrics": {
            "accuracy": 0.8879,
            "f1_score": 0.8,
            "precision_score": 0.7518,
            "recall_score": 0.8548,
            "roc_auc_score": 0.9526
        },
        "val_metrics": {
            "accuracy": 0.9032,
            "f1_score": 0.8352,
            "precision_score": 0.7917,
            "recall_score": 0.8837,
            "roc_auc_score": 0.9632
        }
    },
    "Ethiopia_Tigray_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/1xws3n3i",
        "test_metrics": {
            "accuracy": 0.7936,
            "f1_score": 0.6305,
            "precision_score": 0.6549,
            "recall_score": 0.6078,
            "roc_auc_score": 0.8073
        },
        "val_metrics": {
            "accuracy": 0.8076,
            "f1_score": 0.6757,
            "precision_score": 0.6329,
            "recall_score": 0.7246,
            "roc_auc_score": 0.8533
        }
    },
    "Ethiopia_Tigray_2021": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/2ipmbpo4",
        "test_metrics": {
            "accuracy": 0.8338,
            "f1_score": 0.7426,
            "precision_score": 0.7521,
            "recall_score": 0.7333,
            "roc_auc_score": 0.8635
        },
        "val_metrics": {
            "accuracy": 0.8746,
            "f1_score": 0.78,
            "precision_score": 0.7647,
            "recall_score": 0.7959,
            "roc_auc_score": 0.9142
        }
    },
    "Malawi_2020_September": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/2dh2xut8",
        "test_metrics": {
            "accuracy": 0.8846,
            "f1_score": 0.5909,
            "precision_score": 0.5342,
            "recall_score": 0.661,
            "roc_auc_score": 0.8868
        },
        "val_metrics": {
            "accuracy": 0.8873,
            "f1_score": 0.5909,
            "precision_score": 0.5,
            "recall_score": 0.7222,
            "roc_auc_score": 0.8698
        }
    },
    "Mali_lower_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/316x6lni",
        "test_metrics": {
            "accuracy": 0.7159,
            "f1_score": 0.4539,
            "precision_score": 0.6809,
            "recall_score": 0.3404,
            "roc_auc_score": 0.7572
        },
        "val_metrics": {
            "accuracy": 0.7382,
            "f1_score": 0.5814,
            "precision_score": 0.7937,
            "recall_score": 0.4587,
            "roc_auc_score": 0.8066
        }
    },
    "Mali_upper_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/3axtsg0h",
        "test_metrics": {
            "accuracy": 0.8297,
            "f1_score": 0.3529,
            "precision_score": 0.2206,
            "recall_score": 0.8824,
            "roc_auc_score": 0.8958
        },
        "val_metrics": {
            "accuracy": 0.8006,
            "f1_score": 0.25,
            "precision_score": 0.1467,
            "recall_score": 0.8462,
            "roc_auc_score": 0.889
        }
    },
    "Rwanda_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/1jc6yizd",
        "test_metrics": {
            "accuracy": 0.6989,
            "f1_score": 0.625,
            "precision_score": 0.5114,
            "recall_score": 0.8036,
            "roc_auc_score": 0.7989
        },
        "val_metrics": {
            "accuracy": 0.7196,
            "f1_score": 0.6862,
            "precision_score": 0.5714,
            "recall_score": 0.8586,
            "roc_auc_score": 0.8124
        }
    },
    "Uganda_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/2juzga9q",
        "test_metrics": {
            "accuracy": 0.8509,
            "f1_score": 0.5278,
            "precision_score": 0.413,
            "recall_score": 0.7308,
            "roc_auc_score": 0.9108
        },
        "val_metrics": {
            "accuracy": 0.8458,
            "f1_score": 0.5139,
            "precision_score": 0.4405,
            "recall_score": 0.6167,
            "roc_auc_score": 0.8479
        }
    }
}