{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bef116",
   "metadata": {},
   "source": [
    "## Estimate crop area based on crop mask (single year)\n",
    "\n",
    "**Author**: Hannah Kerner (hkerner@umd.edu)\n",
    "\n",
    "**Description**: This notebook performs the following steps:\n",
    "1. Clips crop mask to a regional boundary (admin1 shape or user-defined bounding box)\n",
    "1. Computes the confusion matrix between the labeled reference sample and the crop mask\n",
    "1. Creates a random stratified sample from the crop mask for labeling in CEO\n",
    "2. Calculates for the crop and noncrop area and accuracy estimates based on [Olofsson et al., 2014](https://www.sciencedirect.com/science/article/abs/pii/S0034425714000704)\n",
    "\n",
    "To be added in the future:\n",
    "- Code for thresholding the crop mask to a binary mask of 0 (noncrop) or 1 (crop)\n",
    "- Code for sub-regional estimates (subsetting the reference sample according to admin2 bounds, e.g.), probably as a separate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81caa17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "#import cartopy.io.shapereader as shpreader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b738350",
   "metadata": {},
   "source": [
    "## Clip crop mask to a regional boundary (admin1 shape or user-defined bounding box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb6b2a",
   "metadata": {},
   "source": [
    "Before you begin, make sure you have taken the following steps:\n",
    "1. Make sure your rasters are projected using the local UTM zone (e.g., EPSG:326XX where XX is the 2-digit UTM zone). The easiest way to reproject a raster is using gdalwarp on the command line:\n",
    "\n",
    "`gdalwarp -t_srs <target_crs> -s_srs <source_crs> -tr 10 10 <source_filename> <dest_filename> -dstnodata 255`\n",
    "\n",
    "2. Clip your rasters to the bounds of your region of interest using a shapefile for the region. The easiest way to do this is also using gdalwarp on the command line:\n",
    "\n",
    "`gdalwarp -cutline <shapefile_name> -crop_to_cutline <source_filename> <dest_filename> -dstnodata -255`\n",
    "\n",
    "If you do not have the shapefile for your ROI downloaded already, you can run the following steps to download one (note: this functionality only available for admin1 level boundaries).\n",
    "\n",
    "If you want to use the dimensions of a bounding box instead of a shapefile, you will have the opportunity to do that later in Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = \"CHN\" # Can be found https://www.iso.org/obp/ui/#search under the Alpha-3 code column\n",
    "regions_of_interest = ['Heilongjiang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in shapefile from natural earth\n",
    "ne_shapefile = shpreader.natural_earth(resolution='10m', category='cultural', name='admin_1_states_provinces')\n",
    "ne_gdf = gpd.read_file(ne_shapefile)\n",
    "\n",
    "if len(regions_of_interest) == 0:\n",
    "    # Select entire country (all regions):\n",
    "    condition = ne_gdf[\"adm1_code\"].str.startswith(country_code)\n",
    "    boundary = ne_gdf[condition].copy()\n",
    "    print(\"Entire country found!\")\n",
    "\n",
    "else:\n",
    "    # Check regions\n",
    "    available_regions = ne_gdf[ne_gdf[\"adm1_code\"].str.startswith(country_code)][\"name\"].tolist()\n",
    "    regions_not_found = [region for region in regions_of_interest if region not in available_regions]\n",
    "\n",
    "    if len(regions_not_found) > 0:\n",
    "        condition = ne_gdf[\"adm1_code\"].str.startswith(country_code)\n",
    "        boundary = None\n",
    "        print(f\"WARNING: {regions_not_found} was not found. Please select regions only seen in below plot.\")\n",
    "    else:\n",
    "        condition = ne_gdf[\"name\"].isin(regions_of_interest)\n",
    "        boundary = ne_gdf[condition].copy()\n",
    "        print(\"All regions found!\")\n",
    "\n",
    "ne_gdf[condition].plot(\n",
    "    column=\"name\", \n",
    "    legend=True, \n",
    "    legend_kwds={'loc': 'lower right'}, \n",
    "    figsize=(10,10)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_gdf.crs = 'EPSG:32xxx' # The CRS code of your map\n",
    "ne_gdf.to_file('/path/to/save.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a217fde",
   "metadata": {},
   "source": [
    "## Load the crop mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c7ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with rio.open(mask_path) as src:\n",
    "    if src.meta['crs'] == 'epsg:4326':\n",
    "        print('''WARNING: The map CRS is EPSG:4326. This means the map unit is degrees \n",
    "              and the pixel-wise areas will not be in meters. You need to reproject the map\n",
    "              to the projection defined for the map's primary UTM zone (e.g., EPSG:32652).''')\n",
    "    if src.meta['dtype'] != 'uint8':\n",
    "        print('''WARNING: The map data type is %s but should be uint8. Make sure the map has\n",
    "              been thresholded to convert to a binary mask of 0 (noncrop) or 1 (crop).''')\n",
    "    else:\n",
    "        print('Map CRS is %s. Loading map into memory.' % src.crs)\n",
    "        crop_map = src.read(1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee82586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the raster from the .tif file as a numpy array\n",
    "# Returns a masked array where the nodata values are masked\n",
    "def load_raster(path, target_crs='epsg:4326', clip_coords=None):\n",
    "    with rio.open(path) as src:\n",
    "        if src.meta['crs'] == 'epsg:4326':\n",
    "            print('''WARNING: The map CRS is EPSG:4326. This means the map unit is degrees \n",
    "                  and the pixel-wise areas will not be in meters. You need to reproject the map\n",
    "                  to the projection defined for the map's primary UTM zone (e.g., EPSG:32652).''')\n",
    "        else:\n",
    "            print('Map CRS is %s. Loading map into memory.' % src.crs)\n",
    "            print(src.meta)\n",
    "            if clip_coords:\n",
    "                raster, out_transform = mask(src, shapes=clip_coords, crop=True)\n",
    "                raster = raster[0]\n",
    "                # Update the metadata\n",
    "                out_meta = src.meta.copy()\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                                 \"height\": raster.shape[0],\n",
    "                                 \"width\": raster.shape[1],\n",
    "                                 \"transform\": out_transform,\n",
    "                                 \"crs\": src.meta['crs']}\n",
    "                               )\n",
    "                return np.ma.masked_equal(raster, src.meta['nodata']), out_meta\n",
    "            else:\n",
    "                raster = src.read(1).astype(np.uint8)\n",
    "                return np.ma.masked_equal(raster, src.meta['nodata']), src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(gdf):\n",
    "    \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\"\n",
    "    import json\n",
    "    return [json.loads(gdf.to_json())['features'][0]['geometry']]\n",
    "\n",
    "# Optionally specify bounding box boundaries to clip to\n",
    "# Note that these boundaries must be in the same CRS as the raster\n",
    "# You can get this from bboxfinder, e.g.: http://bboxfinder.com/#10.277000,36.864900,10.835100,37.191000\n",
    "minx, miny, maxx, maxy = # your optional bbox bounds, e.g.\n",
    "                         # 249141.6217,840652.3433,272783.1953,855138.2342\n",
    "bbox = box(minx, miny, maxx, maxy)\n",
    "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=target_crs)\n",
    "coords = getFeatures(geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = # path to your binary map file, \n",
    "            # e.g. '/gpfs/data1/cmongp1/barker/binary_masks/reprojected/epsg32652_HLJ_2019.tif'\n",
    "    \n",
    "target_crs = 'epsg:xxxxx' # the CRS you want to use (see discussion about CRS in step 1 below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d21452",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_map, crop_map_meta = load_raster(mask_path, target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5027742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the map to make sure it looks as expected\n",
    "# This may take a while depending on the size of the map,\n",
    "# so you may choose not to run this every time.\n",
    "# plt.imshow(crop_map, cmap='YlGn');\n",
    "# plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46aa79",
   "metadata": {},
   "source": [
    "## Calculate the mapped area for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7443f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = src.transform[0]\n",
    "print('The pixel size is %f meters.' % pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3431d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mapped area in pixels or ha\n",
    "def mapped_area(pred_map, unit='pixels', px_size=10):\n",
    "    crop_px = np.where(pred_map.flatten() == 1)\n",
    "    noncrop_px = np.where(pred_map.flatten() == 0)\n",
    "    total = crop_px[0].shape[0] + noncrop_px[0].shape[0]\n",
    "    if unit == 'ha':\n",
    "        # Multiply pixels by area per pixel and convert m to hectares\n",
    "        crop_area = crop_px[0].shape[0] * (px_size*px_size) / 100000\n",
    "        noncrop_area = noncrop_px[0].shape[0] * (px_size*px_size) / 100000\n",
    "    elif unit == 'pixels':\n",
    "        crop_area = int(crop_px[0].shape[0])\n",
    "        noncrop_area = int(noncrop_px[0].shape[0])\n",
    "    elif unit == 'fraction':\n",
    "        crop_area = crop_px[0].shape[0] / total\n",
    "        noncrop_area = noncrop_px[0].shape[0] / total\n",
    "        assert (crop_area + noncrop_area) == 1\n",
    "    return crop_area, noncrop_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_area_frac, noncrop_area_frac = mapped_area(crop_map, unit='fraction')\n",
    "\n",
    "print('Crop area [fraction] = %f' % crop_area_frac)\n",
    "print('Non-crop area [fraction] = %f' % noncrop_area_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_area_px, noncrop_area_px = mapped_area(crop_map)\n",
    "\n",
    "print('Crop area [pixels] = %d' % crop_area_px)\n",
    "print('Non-crop area [pixels] = %d' % noncrop_area_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb92b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_area_px = crop_area_px + noncrop_area_px\n",
    "print('Total area [pixels] = %d' % tot_area_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51965a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_area_ha, noncrop_area_ha = mapped_area(crop_map, unit='ha', px_size=pixel_size)\n",
    "\n",
    "print('Crop area [ha] = %d' % crop_area_ha)\n",
    "print('Non-crop area [ha] = %d' % noncrop_area_ha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f636ff",
   "metadata": {},
   "source": [
    "## Create random stratified reference sample from change map strata following best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6402c2d",
   "metadata": {},
   "source": [
    "First we need to determine the number of total samples we want to label for our reference dataset.\n",
    "\n",
    "We use the method identified by Olofsson et al. in [*Good practices for estimating area and assessing accuracy of land change*](https://www.sciencedirect.com/science/article/pii/S0034425714000704) (eq 13) to determine sample size:\n",
    "\n",
    "n ≈ ( Σ(W<sub>i</sub>S<sub>i</sub>) / S(Ô) )<sup>2</sup>\n",
    "\n",
    "| Where         |                                                      |\n",
    "|---------------|------------------------------------------------------|\n",
    "| W<sub>i</sub> | Mapped proportion of class i                         |\n",
    "| S<sub>i</sub> | Standard deviation √(U<sub>i</sub>(1-U<sub>i</sub>)) |\n",
    "| U<sub>i</sub> | Expected user's accuracy for class i                 |\n",
    "| S(Ô)          | Standard error                                       |\n",
    "| n             | Sample size                                          |\n",
    "\n",
    "\n",
    "If you have already used an independent validation or test set to estimate the user's accuracy for each class, you can plug those values into this equation. If you have not already calculated it, you will need to make a guess (it is better to make a conservative guess since an overestimation may lead to fewer points than are actually needed to achieve low standard errors). See the example calculation below for user's accuracy of both classes of 0.63 and a standard error of 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ac532",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_crop = 0.7\n",
    "u_noncrop = 0.7\n",
    "stderr = 0.02\n",
    "\n",
    "s_crop = np.sqrt(u_crop * (1-u_crop))\n",
    "s_noncrop = np.sqrt(u_noncrop * (1-u_noncrop))\n",
    "\n",
    "n = np.round(((crop_area_frac*s_crop + noncrop_area_frac*s_noncrop) / stderr)**2)\n",
    "\n",
    "print('Num samples: {}'.format(int(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0638e69",
   "metadata": {},
   "source": [
    "We will use a stratified random sample, meaning we will sample some number of points randomly within each of our map strata (the crop and non-crop classes). Refer to Section 5.1.2 in Olofsson et al. for in depth discussion on different sample allocation methods and choose the one that best fits your use case. Below, we use the equal allocation strategy to allocate an approximately equal number of samples to the crop and non-crop map strata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f767348",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_crop = int(n / 2)\n",
    "n_noncrop = int(n - n_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bfc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample allocation:')\n",
    "print('Crop: {}'.format(n_crop))\n",
    "print('Non-crop: {}'.format(n_noncrop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c232543",
   "metadata": {},
   "source": [
    "Now we can randomly draw sample locations using this allocation from each of the map strata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_inds(raster, strata, n):\n",
    "    inds = np.where(raster == strata)\n",
    "    rand_inds = np.random.choice(np.arange(inds[0].shape[0]), size=n, replace=False)\n",
    "    rand_px = inds[0][rand_inds]\n",
    "    rand_py = inds[1][rand_inds]\n",
    "    return rand_px, rand_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noncrop = pd.DataFrame([], columns=['px', 'py', 'pred_class'])\n",
    "df_noncrop['px'], df_noncrop['py'] = random_inds(crop_map, 0, n_noncrop)\n",
    "df_noncrop['pred_class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1aec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crop = pd.DataFrame([], columns=['px', 'py', 'pred_class'])\n",
    "df_crop['px'], df_crop['py'] = random_inds(crop_map, 1, n_crop)\n",
    "df_crop['pred_class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3886951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_noncrop, df_crop]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3563f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of samples in each strata to confirm\n",
    "df_combined.groupby('pred_class').count()['px'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pixel locations to geographic locations\n",
    "with rio.open(mask_path) as src:\n",
    "    for r, row in df_combined.iterrows():\n",
    "        # translate to geographic coordinates\n",
    "        lx, ly = src.xy(row['px'], row['py'])\n",
    "        df_combined.loc[r, 'lx'] = lx\n",
    "        df_combined.loc[r, 'ly'] = ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34534d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframe so the classes are randomized in CEO\n",
    "df_combined = df_combined.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3640f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to a geopandas dataframe\n",
    "gdf = gpd.GeoDataFrame(df_combined, geometry=gpd.points_from_xy(df_combined.lx, df_combined.ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d85e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.crs = target_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74099e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the labels in the local CRS first\n",
    "ref_sample_path_local = '/your/file/path.shp'\n",
    "\n",
    "gdf.to_file(ref_sample_path_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d937836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 4326 for CEO\n",
    "gdf_4326 = gdf.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_4326['PLOTID'] = gdf_4326.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_4326['SAMPLEID'] = gdf_4326.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_4326.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the labels in the CEO format\n",
    "ref_sample_path_ceo = '/your/file/path.shp'\n",
    "gdf_4326[['geometry', 'PLOTID', 'SAMPLEID']].to_file(ref_sample_path_ceo, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57189c62",
   "metadata": {},
   "source": [
    "### Label the reference samples in CEO\n",
    "\n",
    "This step is done in Collect Earth Online. First you need to create a labeling project with the shapefile we just created (two copies for consensus). Once all of the points in both sets have been labeled, come back to the next step.\n",
    "\n",
    "See the instructions for labeling planted area points [here](https://docs.google.com/presentation/d/18bJHMX5M1jIR9NBWIdYeJyo3tG4CL3dNO5vvxOpz5-4/edit#slide=id.p)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7e467",
   "metadata": {},
   "source": [
    "## 4. Load the labeled reference samples\n",
    "\n",
    "There should be two sets of labels for the reference sample. We compare the labels from each set to filter out labels for which the labelers did not agree and thus we can't be confident about the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_set1_path = # path to your CEO Set 1 CSV file, \n",
    "                # e.g. '/gpfs/data1/cmongp1/barker/labeled_ceo/ceo-HLJ-2019-(Set-1)---v3-sample-data-2022-01-21.csv'\n",
    "\n",
    "ceo_set2_path = # path to your CEO Set 2 CSV file, \n",
    "                # e.g. '/gpfs/data1/cmongp1/barker/labeled_ceo/ceo-HLJ-2019-(Set-2)---v3-sample-data-2022-01-21.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_set1 = pd.read_csv(ceo_set1_path)\n",
    "ceo_set1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd57bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ceo_set2 = pd.read_csv(ceo_set2_path)\n",
    "ceo_set2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f26e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes there are slight variations in the labeling question used. We store it here to avoid manual updates.\n",
    "label_question = ceo_set1.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfefd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_set1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaefa5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_set1[ceo_set1[label_question] == 'Crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any NaNs / missing answers\n",
    "ceo_set1[ceo_set1[label_question].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffe3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any NaNs / missing answers\n",
    "ceo_set2[ceo_set2[label_question].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a8b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ceo_set1.shape != ceo_set2.shape:\n",
    "    print('ERROR: The size of the two dataframes does not match. Most likely, there is a duplicate in the plotid column resulting from an error in CEO. You need to delete the duplicate manually before continuing.')\n",
    "    print(ceo_set1[ceo_set1.duplicated(subset=['plotid'])])\n",
    "    print(ceo_set2[ceo_set2.duplicated(subset=['plotid'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the question and thus column name is correct for the project you are working on\n",
    "ceo_agree = ceo_set1[ceo_set1[label_question] == \n",
    "                         ceo_set2[label_question]]\n",
    "\n",
    "print('Number of samples that are in agreement: %d out of %d (%.2f%%)' % \n",
    "          (ceo_agree.shape[0], ceo_set1.shape[0], ceo_agree.shape[0]/ceo_set1.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to a geodataframe\n",
    "ceo_agree_geom = gpd.GeoDataFrame(ceo_agree, geometry=gpd.points_from_xy(ceo_agree.lon, ceo_agree.lat), crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labeling platform CEO requires points to be in EPSG:4326. \n",
    "# Reproject to the same crs as the map.\n",
    "ceo_agree_geom = ceo_agree_geom.to_crs(src.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961dddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot them to make sure they look as expected\n",
    "ceo_agree_geom.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e618d3b",
   "metadata": {},
   "source": [
    "## 5. Get the mapped class for each of the reference samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14580b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, row in ceo_agree_geom.iterrows():\n",
    "    # transform lon, lat to pixel coordinates\n",
    "    lon, lat = row['geometry'].y, row['geometry'].x\n",
    "    px, py = src.index(lat, lon)\n",
    "    ceo_agree_geom.loc[r,'Mapped class'] = crop_map[px, py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_agree_geom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf9f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure none of them are nodata\n",
    "ceo_agree[ceo_agree_geom['Mapped class'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2413eb",
   "metadata": {},
   "source": [
    "## 6. Compute the confusion matrix between the mapped classes and reference labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CEO string label to an integer label\n",
    "ceo_agree_geom.loc[ceo_agree_geom[label_question] == 'Crop', 'Reference label'] = 1\n",
    "ceo_agree_geom.loc[ceo_agree_geom[label_question] == 'Non-crop', 'Reference label'] = 0\n",
    "# Account for alternate spellings that may be pressent\n",
    "ceo_agree_geom.loc[ceo_agree_geom[label_question] == 'Noncrop', 'Reference label'] = 0\n",
    "ceo_agree_geom.loc[ceo_agree_geom[label_question] == 'NonCrop', 'Reference label'] = 0\n",
    "\n",
    "ceo_agree_geom['Reference label'] = ceo_agree_geom['Reference label'].astype(np.uint8)\n",
    "ceo_agree_geom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "y_true = np.array(ceo_agree_geom['Reference label']).astype(np.uint8)\n",
    "y_pred = np.array(ceo_agree_geom['Mapped class']).astype(np.uint8)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print confusion matrix values with element descriptions\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print('True negatives: %d' % tn)\n",
    "print('False positives: %d' % fp)\n",
    "print('False negatives: %d' % fn)\n",
    "print('True positives: %d' % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c620f",
   "metadata": {},
   "source": [
    "## 7. Adjust mapped area using confusion matrix to compute area estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0242d",
   "metadata": {},
   "source": [
    "$W_h$ is the proportion of mapped area for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c324ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_crop = crop_area_px / tot_area_px\n",
    "print('Wh_crop = %f' % wh_crop)\n",
    "\n",
    "wh_noncrop = noncrop_area_px / tot_area_px\n",
    "print('Wh_noncrop = %f' % wh_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d3cb2",
   "metadata": {},
   "source": [
    "Compute the fraction of the proportional area of each class that was mapped as each category in the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_area = tp / (tp + fp) * wh_crop\n",
    "fp_area = fp / (tp + fp) * wh_crop\n",
    "fn_area = fn / (fn + tn) * wh_noncrop\n",
    "tn_area = tn / (fn + tn) * wh_noncrop\n",
    "\n",
    "print('%f \\t %f \\n %f \\t %f' % (tp_area, fp_area, fn_area, tn_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75bf8f",
   "metadata": {},
   "source": [
    "$U_i$ is the user's accuracy (i.e., precision) for each mapped class. We calculate it here in terms of proportion of area computed in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_crop = tp_area / (tp_area + fp_area)\n",
    "print('U_crop = %f' % u_crop)\n",
    "\n",
    "u_noncrop = tn_area / (tn_area + fn_area)\n",
    "print('U_noncrop = %f' % u_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c052246",
   "metadata": {},
   "source": [
    "$V(U_i)$ is the estimated variance of user accuracy for each mapped class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_u_crop = u_crop * (1-u_crop) / (tp + fp)\n",
    "print('V(U)_crop = %f' % v_u_crop)\n",
    "\n",
    "v_u_noncrop = u_noncrop * (1-u_noncrop) / (fn + tn)\n",
    "print('V(U)_noncrop = %f' % v_u_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2d6b16",
   "metadata": {},
   "source": [
    "$S(U_i)$ is the estimated standard error of user accuracy for each mapped class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_u_crop = np.sqrt(v_u_crop)\n",
    "print('S(U)_crop = %f' % s_u_crop)\n",
    "\n",
    "s_u_noncrop = np.sqrt(v_u_noncrop)\n",
    "print('S(U)_noncrop = %f' % s_u_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cac48e",
   "metadata": {},
   "source": [
    "Get the 95% confidence interval for User's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e37f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_crop_err = s_u_crop * 1.96\n",
    "print('95%% CI of User accuracy for crop = %f' % u_crop_err)\n",
    "\n",
    "u_noncrop_err = s_u_noncrop * 1.96\n",
    "print('95%% CI of User accuracy for noncrop = %f' % u_noncrop_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcfc1c",
   "metadata": {},
   "source": [
    "$P$ is the producer's accuracy (i.e., recall). We calculate it here in terms of proportion of area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60857718",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_crop = tp_area / (tp_area + fn_area)\n",
    "print('P_crop = %f' % p_crop)\n",
    "\n",
    "p_noncrop = tn_area / (tn_area + fp_area)\n",
    "print('P_noncrop = %f' % p_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78580033",
   "metadata": {},
   "source": [
    "$N_j$ is the estimated marginal total number of pixels of each reference class $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ab5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_j_crop = (crop_area_px * tp) / (tp + fp) + (noncrop_area_px * fn) / (fn + tn)\n",
    "print('N_j_crop = %f' % n_j_crop)\n",
    "\n",
    "n_j_noncrop = (crop_area_px * fp) / (tp + fp) + (noncrop_area_px * tn) / (fn + tn)\n",
    "print('N_j_crop = %f' % n_j_noncrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff335be",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr1_crop = crop_area_px**2 * (1-p_crop)**2 * u_crop * (1-u_crop) / (tp + fp - 1)\n",
    "print('expr1 crop = %f' % expr1_crop)\n",
    "\n",
    "expr1_noncrop = noncrop_area_px**2 * (1-p_noncrop)**2 * u_noncrop * (1-u_noncrop) / (fp + tn - 1)\n",
    "print('expr1 noncrop = %f' % expr1_noncrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72678e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: depending on the size of your map, you may get an overflow warning here, e.g.\n",
    "# RuntimeWarning: overflow encountered in long_scalars\n",
    "\n",
    "expr2_crop = p_crop**2 * (noncrop_area_px**2 * fn / (fn + tn) * (1 - fn / (fn + tn)) / (fn + tn - 1))\n",
    "print('expr2 crop = %f' % expr2_crop)\n",
    "\n",
    "expr2_noncrop = p_crop**2 * (crop_area_px**2 * fp / (fp + tp) * (1 - fp / (fp + tp)) / (fp + tp - 1))\n",
    "print('expr2 noncrop = %f' % expr2_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54200296",
   "metadata": {},
   "source": [
    "$V(P_i)$ is the estimated variance of producer's accuracy for each mapped class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfe1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_p_crop = (1 / n_j_crop**2) * (expr1_crop + expr2_crop)\n",
    "print('V(P) crop = %f' % v_p_crop)\n",
    "\n",
    "v_p_noncrop = (1 / n_j_noncrop**2) * (expr1_noncrop + expr2_noncrop)\n",
    "print('V(P) noncrop = %f' % v_p_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20562ea9",
   "metadata": {},
   "source": [
    "$S(P_i)$ is the estimated standard error of producer accuracy for each mapped class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: depending on the size of your map, you may get an overflow warning here, e.g.\n",
    "# RuntimeWarning: overflow encountered in long_scalars\n",
    "\n",
    "s_p_crop = np.sqrt(v_p_crop)\n",
    "print('S(P) crop = %f' % s_p_crop)\n",
    "\n",
    "s_p_noncrop = np.sqrt(v_p_noncrop)\n",
    "print('S(P) noncrop = %f' % s_p_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd606331",
   "metadata": {},
   "source": [
    "Get the 95% confidence interval for Producer's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f88562",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_crop_err = s_p_crop * 1.96\n",
    "print('95%% CI of Producer accuracy for crop = %f' % p_crop_err)\n",
    "\n",
    "p_noncrop_err = s_p_noncrop * 1.96\n",
    "print('95%% CI of Producer accuracy for noncrop = %f' % p_noncrop_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8734e6",
   "metadata": {},
   "source": [
    "$O$ is the overall accuracy. We calculate it here in terms of proportion of area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tp_area + tn_area\n",
    "print('Overall accuracy = %f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6886a49",
   "metadata": {},
   "source": [
    "$V(O)$ is the estimated variance of the overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_acc = wh_crop**2 * u_crop * (1-u_crop) / (tp + fp - 1) + \\\n",
    "        wh_noncrop**2 * u_noncrop * (1-u_noncrop) / (fn + tn - 1)\n",
    "print('V(O) = %f' % v_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b1ad3",
   "metadata": {},
   "source": [
    "$S(O)$ is the estimated standard error of the overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae08bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_acc = np.sqrt(v_acc)\n",
    "print('S(O) = %f' % s_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3f37a",
   "metadata": {},
   "source": [
    "Get the 95% confidence interval for overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_err = s_acc * 1.96\n",
    "print('95%% CI of overall accuracy = %f' % acc_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6587cfc",
   "metadata": {},
   "source": [
    "$A_{pixels}$ is the adjusted map area in units of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pixels_crop = tot_area_px * (tp_area + fn_area)\n",
    "print('A^[pixels] crop = %f' % a_pixels_crop)\n",
    "\n",
    "a_pixels_noncrop = tot_area_px * (tn_area + fp_area)\n",
    "print('A^[pixels] noncrop = %f' % a_pixels_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7347e68c",
   "metadata": {},
   "source": [
    "$A_{ha}$ is the adjusted map area in units of hectares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a732fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ha_crop = a_pixels_crop * (pixel_size*pixel_size) / (100*100)\n",
    "print('A^[ha] crop = %f' % a_ha_crop)\n",
    "\n",
    "a_ha_noncrop = a_pixels_noncrop * (pixel_size*pixel_size) / (100*100)\n",
    "print('A^[ha] noncrop = %f' % a_ha_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93e4c2",
   "metadata": {},
   "source": [
    "The following equations are used to estimate the standard error for the area. They are based on the calculations in Olofsson et al., 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfeb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_pk_crop = np.sqrt((wh_crop * tp_area - tp_area**2) / (tp + fp - 1) + \\\n",
    "                     (wh_noncrop * fn_area - fn_area**2) / (fn + tn - 1)) * tot_area_px\n",
    "print('S_pk_crop = %f' % S_pk_crop)\n",
    "\n",
    "S_pk_noncrop = np.sqrt((wh_crop * fp_area - fp_area**2) / (tp + fp - 1) + \\\n",
    "                        (wh_noncrop * tn_area - tn_area**2) / (fn + tn - 1)) * tot_area_px\n",
    "print('S_pk_noncrop = %f' % S_pk_noncrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8913bcae",
   "metadata": {},
   "source": [
    "Multiply $S(p_k)$ by 1.96 to get the margin of error for the 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49665a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pixels_crop_err = S_pk_crop * 1.96\n",
    "print('Crop area standard error 95%% confidence interval [pixels] = %f' % a_pixels_crop_err)\n",
    "\n",
    "a_pixels_noncrop_err = S_pk_noncrop * 1.96\n",
    "print('Non-crop area standard error 95%% confidence interval [pixels] = %f' % a_pixels_noncrop_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ha_crop_err = a_pixels_crop_err * (pixel_size**2) / (100**2)\n",
    "print('Crop area standard error 95%% confidence interval [ha] = %f' % a_ha_crop_err)\n",
    "\n",
    "a_ha_noncrop_err = a_pixels_noncrop_err * (pixel_size**2) / (100**2)\n",
    "print('Non-crop area standard error 95%% confidence interval [ha] = %f' % a_ha_noncrop_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439e81e",
   "metadata": {},
   "source": [
    "Summary of the final estimates of accuracy and area with standard error at 95% confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de476540",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame([[a_ha_crop, a_ha_noncrop],\n",
    "                        [a_ha_crop_err, a_ha_noncrop_err],\n",
    "                        [u_crop, u_noncrop],\n",
    "                        [u_crop_err, u_noncrop_err],\n",
    "                        [p_crop, p_noncrop],\n",
    "                        [p_crop_err, p_noncrop_err],\n",
    "                        [acc, acc],\n",
    "                        [acc_err, acc_err]\n",
    "                       ],\n",
    "                       index=pd.Index(['Estimated area [ha]', '95% CI of area [ha]', 'User accuracy',\n",
    "                                       '95% CI of user acc', 'Producer accuracy', '95% CI of prod acc',\n",
    "                                       'Overall accuracy', '95% CI of overall acc']),\n",
    "                       columns=['Crop', 'Non-crop'])\n",
    "\n",
    "summary.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
