# syntax = docker/dockerfile:experimental
FROM pytorch/torchserve:0.4.2-cpu as base

USER root

FROM base as reqs
COPY gcp/inference/requirements.txt requirements.txt
RUN pip3 install --upgrade pip
RUN pip install -r requirements.txt
RUN pip3 install torch==1.9.0+cpu -f https://download.pytorch.org/whl/torch_stable.html

FROM reqs as build-torchserve
COPY gcp/inference/handler.py /home/model-server

# Ensures that everytime models.dvc is updated 
# This following docker steps are rerun
COPY data/models.dvc /home/model-server
COPY data/models/*.pt /home/model-server

WORKDIR /home/model-server

ARG MODELS
RUN for m in $MODELS; \
    do torch-model-archiver \
    --model-name $m \
    --version 1.0 \
    --serialized-file $m.pt \
    --handler handler.py \
    --export-path=model-store; \
    done

ADD gcp/inference/start.sh /usr/local/bin/start.sh
RUN chmod 777 /usr/local/bin/start.sh
ENV MODELS ${MODELS}
CMD ["/usr/local/bin/start.sh", "\"${MODELS}\""]


