{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "778ff440",
      "metadata": {
        "id": "778ff440"
      },
      "source": [
        "# Intercomparison\n",
        "\n",
        "**Author:**\n",
        "\n",
        "**Last updated:**\n",
        "\n",
        "**Description:** Runs intercomparison for [Country Year]\n",
        "\n",
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb42d13c",
      "metadata": {
        "id": "fb42d13c"
      },
      "outputs": [],
      "source": [
        "# !earthengine authenticate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hZ8qzSlB75kl",
      "metadata": {
        "id": "hZ8qzSlB75kl"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/nasaharvest/crop-mask.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25d6ff7",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install cartopy -qq\n",
        "!pip install rasterio -qq\n",
        "!pip install dvc[gs] -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9907f9a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9907f9a5",
        "outputId": "c9bf6e76-a345-4f21-873c-f804bc9465f4"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import geopandas as gpd\n",
        "from pathlib import Path\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=\"bsos-geog-harvest1\")\n",
        "\n",
        "sys.path.append(\"../..\")\n",
        "\n",
        "from src.compare_covermaps import TARGETS, filter_by_bounds, generate_report, CLASS_COL, COUNTRY_COL, get_ensemble_area\n",
        "from src.compare_covermaps import TEST_COUNTRIES, TEST_CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61ea4f8",
      "metadata": {
        "id": "c61ea4f8"
      },
      "source": [
        "## 2. Read in evaluation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f75e567",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7f75e567",
        "outputId": "6bc628a4-b5b9-46f7-deae-4e19bd4cfc7e"
      },
      "outputs": [],
      "source": [
        "country = \"<COUNTRY STRING GOES HERE>\"\n",
        "\n",
        "if country not in TEST_CODE:\n",
        "    print(f\"WARNING: {country} not found in TEST_CODE in src/compare_covermaps.py\")\n",
        "if country not in TEST_COUNTRIES:\n",
        "    print(f\"WARNING: {country} not found in TEST_COUNTRIES in src/compare_covermaps.py\")\n",
        "if country not in TEST_CODE or country not in TEST_COUNTRIES:\n",
        "    print(\"Please update src/compare_covermaps.py and restart the notebook.\")\n",
        "else:\n",
        "    country_code = TEST_CODE[country]\n",
        "    # dataset_path = \"../\" + TEST_COUNTRIES[country]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vbVX8gFd_N3J",
      "metadata": {
        "id": "vbVX8gFd_N3J"
      },
      "outputs": [],
      "source": [
        "# !dvc pull data/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df7a7aaf",
      "metadata": {},
      "outputs": [],
      "source": [
        "ceo_set1 = \"<PATH TO CEO REFERENCE SAMPLE SET1>\"\n",
        "ceo_set2 = \"<PATH TO CEO REFERENCE SAMPLE SET2>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c6cea9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def reference_sample_agree(ceo_ref1, ceo_ref2):\n",
        "    ceo_ref1 = pd.read_csv(ceo_ref1)\n",
        "    ceo_ref2 = pd.read_csv(ceo_ref2)\n",
        "\n",
        "    assert ceo_ref1.columns[-1] == ceo_ref2.columns[-1]\n",
        "\n",
        "    label_question = ceo_ref1.columns[-1]\n",
        "\n",
        "    print(f\"Number of NANs/ missing answers in set 1: {ceo_ref1[label_question].isna().sum()}\")\n",
        "    print(f\"Number of NANs/ missing answers in set 2: {ceo_ref2[label_question].isna().sum()}\")\n",
        "\n",
        "    if ceo_ref1.shape[0] != ceo_ref2.shape[0]:\n",
        "        print(\"The number of rows in the reference sets are not equal.\")\n",
        "        print(\"Checking for duplictes on 'plotid'..\")\n",
        "        print(\n",
        "            \" Number of duplicated in set 1: %s\" % ceo_ref1[ceo_ref1.plotid.duplicated()].shape[0]\n",
        "        )\n",
        "        print(\n",
        "            \" Number of duplicated in set 2: %s\" % ceo_ref2[ceo_ref2.plotid.duplicated()].shape[0]\n",
        "        )\n",
        "        print(\"Removing duplicates and keeping the first...\")\n",
        "        ceo_ref1 = ceo_ref1.drop_duplicates(subset=\"plotid\", keep=\"first\")\n",
        "        ceo_ref2 = ceo_ref2.drop_duplicates(subset=\"plotid\", keep=\"first\")\n",
        "\n",
        "        ceo_ref1.set_index(\"plotid\", inplace=True)\n",
        "        ceo_ref2.set_index(\"plotid\", inplace=True)\n",
        "    else:\n",
        "        print(\"The number of rows in the reference sets are equal.\")\n",
        "\n",
        "    ceo_agree = ceo_ref1[ceo_ref1[label_question] == ceo_ref2[label_question]]\n",
        "\n",
        "    print(\n",
        "        \"Number of samples that are in agreement: %d out of %d (%.2f%%)\"\n",
        "        % (\n",
        "            ceo_agree.shape[0],\n",
        "            ceo_ref1.shape[0],\n",
        "            ceo_agree.shape[0] / ceo_ref1.shape[0] * 100,\n",
        "        )\n",
        "    )\n",
        "    ceo_agree_geom = gpd.GeoDataFrame(\n",
        "        ceo_agree,\n",
        "        geometry=gpd.points_from_xy(ceo_agree.lon, ceo_agree.lat),\n",
        "        crs=\"EPSG:4326\",\n",
        "    )\n",
        "\n",
        "    label_responses = ceo_agree_geom[label_question].unique()\n",
        "    assert len(label_responses) == 2\n",
        "\n",
        "    for r, row in ceo_agree_geom.iterrows():\n",
        "\n",
        "        try:\n",
        "            if (\n",
        "                row[label_question].lower() == \"crop\"\n",
        "                or row[label_question].lower() == \"cropland\"\n",
        "                or row[label_question].lower() == \"planted\"\n",
        "            ):\n",
        "                ceo_agree_geom.loc[r, CLASS_COL] = 1\n",
        "            elif(\n",
        "                row[label_question].lower() == \"non-crop\"\n",
        "                or row[label_question].lower() == \"non-cropland\"\n",
        "                or row[label_question].lower() == \"not planted\"\n",
        "            ):\n",
        "                ceo_agree_geom.loc[r, CLASS_COL] = 0\n",
        "        except IndexError:\n",
        "            ceo_agree_geom.loc[r, CLASS_COL] = 255\n",
        "    \n",
        "    ceo_agree_geom = ceo_agree_geom[ceo_agree_geom[CLASS_COL] != 255]\n",
        "\n",
        "    ceo_agree_geom[CLASS_COL] = ceo_agree_geom[CLASS_COL].astype(int)\n",
        "    ceo_agree_geom[COUNTRY_COL] = country\n",
        "    ceo_agree_geom = ceo_agree_geom[['lat','lon',CLASS_COL, COUNTRY_COL, 'geometry']]\n",
        "    \n",
        "    return ceo_agree_geom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6745bf0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "gdf = reference_sample_agree(ceo_set1,ceo_set2)\n",
        "gdf = filter_by_bounds(country_code=country_code, gdf=gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d313baa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2d313baa",
        "outputId": "82eca2f6-b19d-4f48-c8f8-8789b671fb89"
      },
      "outputs": [],
      "source": [
        "# if not Path(dataset_path).exists():\n",
        "#     print(f\"WARNING: Dataset: {dataset_path} not found, run `dvc pull data/datasets from root.\")\n",
        "# else:\n",
        "#     df = pd.read_csv(dataset_path)[[\"lat\", \"lon\", \"class_probability\", \"subset\"]]\n",
        "#     df = df[(df[\"class_probability\"] != 0.5)].copy()\n",
        "#     # use only test data because validation points used for harvest-dev map\n",
        "#     df = df[df[\"subset\"] == \"testing\"].copy()\n",
        "#     df[CLASS_COL] = (df[\"class_probability\"] > 0.5).astype(int)\n",
        "#     df[COUNTRY_COL] = country\n",
        "\n",
        "#     gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat), crs=\"epsg:4326\")\n",
        "#     gdf = filter_by_bounds(country_code=country_code, gdf=gdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31341d98",
      "metadata": {
        "id": "31341d98"
      },
      "source": [
        "## 3. Run intercomparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ImkKe6cEB4aB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ImkKe6cEB4aB",
        "outputId": "1735fb12-fff5-4db1-e6c7-5ec405510063"
      },
      "outputs": [],
      "source": [
        "gdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c4cc0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "54c4cc0f",
        "outputId": "9c0dde81-9fe7-4b95-ed84-cf2e843a8bbb"
      },
      "outputs": [],
      "source": [
        "TARGETS = {k:v for k,v in TARGETS.items()}\n",
        "for k, v in TARGETS.items():\n",
        "    if country not in v.countries:\n",
        "        continue\n",
        "    if v.year is None:\n",
        "        v.year = v.collection_years[v.countries.index(country)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1oQjubrHjkBi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1oQjubrHjkBi",
        "outputId": "281b6668-e99c-420a-cdf9-dd6a6305b67c"
      },
      "outputs": [],
      "source": [
        "reference_year = \"<YEAR INTEGER GOES HERE>\"\n",
        "TARGETS = {k: v for k, v in TARGETS.items() if v.year in [reference_year - 1, reference_year, reference_year + 1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e241d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "98e241d2",
        "outputId": "f4eac0c8-86d5-4145-fb60-e82795da095c"
      },
      "outputs": [],
      "source": [
        "for cropmap in TARGETS.values():\n",
        "    if country not in cropmap.countries:\n",
        "        continue\n",
        "    print(f\"[{country}] sampling \" + cropmap.title + \"...\")\n",
        "    map_sampled = cropmap.extract_test(gdf).copy()\n",
        "    gdf = pd.merge(gdf, map_sampled, on=[\"lat\", \"lon\"], how=\"left\")\n",
        "    gdf.drop_duplicates(inplace=True)  # TODO find why points get duplicated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a0f536",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "95a0f536",
        "outputId": "194c8876-85b9-4c4b-e96f-14135eb83efc"
      },
      "outputs": [],
      "source": [
        "a_j = {}\n",
        "for cropmap in TARGETS.values():\n",
        "    if country not in cropmap.countries:\n",
        "        continue\n",
        "    print(f\"[{country}] calculating pixel area for \" + cropmap.title + \"...\")\n",
        "    a_j[cropmap.title] = cropmap.compute_map_area(country, export=True, dataset_name=cropmap.title).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fJPzvOeUo9G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5fJPzvOeUo9G",
        "outputId": "ca430174-f6b7-4165-e05d-b60bea834408"
      },
      "outputs": [],
      "source": [
        "# update a_j values with exported values\n",
        "for cropmap in a_j.keys():\n",
        "    try:\n",
        "        area_df = pd.read_csv(f'./Crop_NonCrop_Area_Sum_Export-Kenya-{cropmap}.csv')\n",
        "    except:\n",
        "        continue\n",
        "    crop_area = int(area_df['crop_sum'][0])\n",
        "    noncrop_area = int(area_df['noncrop_sum'][0])\n",
        "    a_j[cropmap] = np.array([noncrop_area, crop_area])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e853cd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# update a_j values with exported values\n",
        "for cropmap in a_j.keys():\n",
        "    try:\n",
        "        area_df = pd.read_csv(f'./Crop_NonCrop_Area_Sum_Export-Kenya-{cropmap}.csv')\n",
        "    except:\n",
        "        continue\n",
        "    crop_area = int(area_df['crop_sum'][0])\n",
        "    noncrop_area = int(area_df['noncrop_sum'][0])\n",
        "    a_j[cropmap] = np.array([noncrop_area, crop_area])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zyR4qCJ49Rh5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zyR4qCJ49Rh5",
        "outputId": "687d7607-e723-4097-9d70-a3b65e149b26"
      },
      "outputs": [],
      "source": [
        "# Change None to nan\n",
        "a_j = {k: np.array([np.nan, np.nan]) if np.any(v == None) else v for k,v in a_j.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LY6Q_QtUgME_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LY6Q_QtUgME_",
        "outputId": "38c43d9d-f9a4-4784-ad57-70c9bfc220c4"
      },
      "outputs": [],
      "source": [
        "from src.area_utils import compute_area_estimate, compute_area_error_matrix, compute_std_p_i\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oojPqwSboiWU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oojPqwSboiWU",
        "outputId": "bf0c96a8-477b-4e7b-9e3c-e675aba506b8"
      },
      "outputs": [],
      "source": [
        "# compute area estimate for each map\n",
        "def compute_area_estimate(dataset, true, pred, a_j, resolution):\n",
        "    cm = confusion_matrix(true, pred)\n",
        "    total_px = a_j.sum()\n",
        "    w_j = a_j / total_px\n",
        "\n",
        "    am = compute_area_error_matrix(cm, w_j)\n",
        "    a_i = am.sum(axis=1)\n",
        "    std_a_i = compute_std_p_i(w_j, am, cm)\n",
        "    err_a_i = 1.96 * std_a_i\n",
        "\n",
        "    a_px = total_px * a_i\n",
        "    err_px = err_a_i * total_px\n",
        "    return pd.DataFrame(\n",
        "        data={\n",
        "            \"dataset\": dataset,\n",
        "            \"area_ha\": a_px[1] * (resolution**2) / (100**2),\n",
        "            \"err_ha\": err_px[1] * (resolution**2) / (100**2),\n",
        "        },\n",
        "        index=[0],\n",
        "    ).round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ti5ZXmbyn6Mm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "ti5ZXmbyn6Mm",
        "outputId": "a73ecb9c-d41e-4968-e987-041cab46daea"
      },
      "outputs": [],
      "source": [
        "comparisons = []\n",
        "area_est = []\n",
        "for cropmap in TARGETS.values():\n",
        "    cropmap, resolution = cropmap.title, cropmap.resolution\n",
        "    if cropmap not in gdf.columns:\n",
        "        continue\n",
        "    temp = gdf[[CLASS_COL, cropmap]].dropna()\n",
        "    area = compute_area_estimate(cropmap, temp[CLASS_COL], temp[cropmap], a_j[cropmap], resolution)\n",
        "    comparison = generate_report(cropmap, country, temp[CLASS_COL], temp[cropmap], a_j[cropmap], area_weighted=True)\n",
        "    comparisons.append(comparison)\n",
        "    area_est.append(area)\n",
        "\n",
        "comparisons = pd.concat(comparisons).set_index(['dataset'])\n",
        "area_est = pd.concat(area_est).set_index(['dataset'])\n",
        "\n",
        "results = comparisons.merge(area_est, on='dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QrAgv7pP1lcz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QrAgv7pP1lcz",
        "outputId": "6f33c955-6ceb-4295-84ed-4aaf65c1512f"
      },
      "outputs": [],
      "source": [
        "results.to_csv('results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nAj0p7VS1_2K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "nAj0p7VS1_2K",
        "outputId": "78579510-3b2c-4a4e-b9e0-97cb2f9837bc"
      },
      "outputs": [],
      "source": [
        "results[['crop_f1','accuracy','std_acc','crop_recall_pa','std_crop_pa','crop_precision_ua','std_crop_ua','area_ha','err_ha']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa969373",
      "metadata": {
        "id": "fa969373"
      },
      "source": [
        "## 4. Plot area estimate and error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fraQjcTMpTwp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "fraQjcTMpTwp",
        "outputId": "0b4817bc-04b7-45ea-a267-0777448edc38"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "n = len(results)\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, n))\n",
        "\n",
        "ax.barh(\n",
        "    results.index,\n",
        "    results[\"area_ha\"],\n",
        "    xerr=results[\"err_ha\"],\n",
        "    align=\"center\",\n",
        "    alpha=0.5,\n",
        "    ecolor=\"black\",\n",
        "    capsize=10,\n",
        "    color=colors,\n",
        ")\n",
        "\n",
        "for i, (value, err) in enumerate(zip(results[\"area_ha\"], results[\"err_ha\"])):\n",
        "    ax.text(value, i, f\"{value} ± {err}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "ax.set_ylabel(\"Area (ha)\")\n",
        "ax.set_title(\"Area of cropland\")\n",
        "ax.spines[\"right\"].set_visible(False)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
